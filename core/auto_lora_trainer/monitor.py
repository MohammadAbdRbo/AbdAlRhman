import time
import os
from core.auto_lora_trainer.dataset_builder import build_dataset
from core.auto_lora_trainer.lora_trainer import train
from core.auto_lora_trainer.adapter_loader import load_model_with_lora

CHECK_INTERVAL = 300  # 5 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¨ÙŠÙ† ÙƒÙ„ ÙØ­Øµ
LOADED_SAMPLES_FILE = "core/auto_lora_trainer/last_count.txt"

def get_last_count():
    if os.path.exists(LOADED_SAMPLES_FILE):
        with open(LOADED_SAMPLES_FILE, "r") as f:
            return int(f.read().strip())
    return 0

def save_last_count(count):
    with open(LOADED_SAMPLES_FILE, "w") as f:
        f.write(str(count))

def monitor_loop():
    print("ğŸ” Monitoring started...")
    while True:
        print("ğŸ” Checking for new data...")
        if build_dataset():  # Ø¥Ø°Ø§ ØªÙ… Ø¨Ù†Ø§Ø¡ dataset Ø¬Ø¯ÙŠØ¯
            print("ğŸ“Š Starting fine-tuning...")
            train()

            print("ğŸ§  Reloading LoRA into active model...")
            load_model_with_lora()

            print("âœ… Fine-tune cycle complete.\n")
        else:
            print("â„¹ï¸ Not enough new messages yet.\n")
        time.sleep(CHECK_INTERVAL)

if __name__ == "__main__":
    monitor_loop()

